{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0\\. Background\n",
        "\n",
        "*   You have been given a marketing dataset for a bank and you have been tasked with predicting the outcome of a marketing campaign\n",
        "\n",
        "*   You have a sample dataset with an <font color=\"red\">y</h1></font> target.  \n",
        "\n",
        "\n",
        "<font color=\"red\"><h1> PRACTICE LAB </h1></font>\n",
        "\n",
        "This is a Kaggle dataset and additional information on the dataset can be found at this link https://www.kaggle.com/datasets/prakharrathi25/banking-dataset-marketing-targets\n",
        "\n"
      ],
      "metadata": {
        "id": "kBIHsSz_XVOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1\\. Load the Dataset into a Pandas DataFrame"
      ],
      "metadata": {
        "id": "FCdL0KFBME-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zpZ1DR1Gs-Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmN27mfvJYF8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Project Directory path\n",
        "project_dir = 'drive/MyDrive/UW.8740/Lab Tests/Lab2/'"
      ],
      "metadata": {
        "id": "ij-ghM7dJpK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(project_dir+ 'train.csv')\n",
        "test = pd.read_csv(project_dir+ 'test.csv')"
      ],
      "metadata": {
        "id": "YPTafCxgJ1h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "uBkSMgQOI-qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([train, test])"
      ],
      "metadata": {
        "id": "er3xFks7LlDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1\\.1 Display the top 5 rows and bottom 5 rows of the DataFrame\n",
        "\n",
        "<font color=\"red\"><h1> <Submit Answer Below [1]:</h1></font>\n"
      ],
      "metadata": {
        "id": "tgEnrQIDSeHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Z7l2DH9ZOmNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2\\.Data Exploration"
      ],
      "metadata": {
        "id": "O18JZROtUSAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\\.1 Identify the number of missing nulls in columns\n",
        "\n",
        "<font color=\"red\"><h1>Submit Answer Below [2]:</h1></font>"
      ],
      "metadata": {
        "id": "3XcJOE_hMXjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "u-rctyd7MhPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "fA_1b-q6VXgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "DJlKbGPQdWmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\\.2 Identify the most frequently occurring job, education, and marital status in your dataset\n",
        "\n",
        "<font color=\"red\"><h1>Submit Answer Below [3] :</h1></font>"
      ],
      "metadata": {
        "id": "smpCkCTxoUjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "YszeVjgzXcHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "0vsgXp82fqk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()[df.nunique()<=20]"
      ],
      "metadata": {
        "id": "4PhccWWRranO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\\.3 Display the unique values of all columns with less than 20 unique values to confirm that they should be considered categorical.\n",
        "\n",
        "<font color=\"red\"><h1>Submit Answer Below [4] :</h1></font>"
      ],
      "metadata": {
        "id": "xeIi-EALokSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.columns:\n",
        "    if (df[column].nunique() < 20):\n",
        "        print(\"Column:\", column)\n",
        "        print(\"Number of Unique Values:\", df[column].nunique())\n",
        "        print(\"Unique values:\", df[column].unique())\n",
        "        print(\"Most Frequent Value:\", df[column].mode()[0])\n",
        "        print('*' * 80)"
      ],
      "metadata": {
        "id": "xhZvdqN10FGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3\\.Pre-process the data"
      ],
      "metadata": {
        "id": "E-fYjUbbYPf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3\\.1 Organize your columns into Catogorical features, numeric features and target variable\n"
      ],
      "metadata": {
        "id": "5ltMv5mPYdnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['y']\n",
        "X = df.drop('y', axis=1)"
      ],
      "metadata": {
        "id": "D0dEU7OoVN-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3\\.2 Feature Transformation\n",
        "\n",
        "\n",
        "*   One Hot Encoding for Categorical Features.  You may include binary features in the one hot encoding to simplify your code\n",
        "\n",
        "* You can drop the month column to simplify your code\n",
        "\n",
        "* Use LabelEncoder to convert the y column from (yes/no) to (0/1)\n",
        "\n",
        "\n",
        "<font color=\"red\"><h1>Submit Answer Below [5] :</h1></font>"
      ],
      "metadata": {
        "id": "mkrGAxNHk3L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Pnso0-73ht9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop([\"month\"], axis = 1)"
      ],
      "metadata": {
        "id": "ugJUt9bgjfI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['job', 'marital', 'education', 'default',\n",
        "                        'housing', 'loan', 'contact', 'poutcome']"
      ],
      "metadata": {
        "id": "JjItC0MkZL25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "X = preprocessor.fit_transform(X)"
      ],
      "metadata": {
        "id": "Ysa0EK8xk2bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "Tnf6AMuMlqAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4\\. Train Predictive Classification Models\n",
        "\n",
        "Split your data to (80% Training/20% Testing)\n",
        "\n",
        "Train the three classifiers with no optimization.\n",
        "\n",
        "Report the following for all classifiers :\n",
        "\n",
        "*   Confusion Matrix\n",
        "*   Accuracy Score\n",
        "*   AUC Score\n",
        "\n",
        "\n",
        "\n",
        "<font color=\"red\"><h1>Submit Answer Below [6] :</h1></font>"
      ],
      "metadata": {
        "id": "YjHfPrJ8rEyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SnW_seL4lSPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################\n",
        "# Accuracy Metric\n",
        "###############################################################\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "YsXRQFkAltbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4\\.1 Decision Tree"
      ],
      "metadata": {
        "id": "DyNjUDQnsbcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8lhqp1OblWfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_test_pred = dt_clf.predict(X_test)\n",
        "print(f'Area under ROC curve: {roc_auc_score(y_test, y_test_pred): 0.4f}')\n",
        "print(f'Accuracy {accuracy_score(y_test, y_test_pred): 0.4f}')\n",
        "print(f'Weigted F1 score {f1_score(y_test, y_test_pred, average=\"weighted\"): 0.4f}')\n",
        "print(classification_report(y_test, y_test_pred, digits=4))\n",
        "pd.DataFrame(confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "print('\\nROC curve')\n",
        "probs = dt_clf.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
        "auc_score = roc_auc_score(y_test, probs)\n",
        "print(\"AUC Score:\", auc_score)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='red')  # Diagonal line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DBXgKGXllwuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4\\.2 Support Vector Machine"
      ],
      "metadata": {
        "id": "VqM_uiMCsoWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(gamma='auto')\n",
        "svm = svm.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "1C8q-GE0ojz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_svm_pred = svm.predict(X_test)\n",
        "print(f'Area under ROC curve: {roc_auc_score(y_test, y_svm_pred): 0.4f}')\n",
        "print(f'Accuracy {accuracy_score(y_test, y_svm_pred): 0.4f}')\n",
        "print(f'Weigted F1 score {f1_score(y_test, y_svm_pred, average=\"weighted\"): 0.4f}')\n",
        "print(classification_report(y_test, y_svm_pred, digits=4))\n",
        "pd.DataFrame(confusion_matrix(y_test, y_svm_pred))"
      ],
      "metadata": {
        "id": "l6VPU2A2oprO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4\\.1 Logistic Regression"
      ],
      "metadata": {
        "id": "7DDzsH2Mss5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logit = LogisticRegression(max_iter=1000)\n",
        "X_test.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "x35W46Ylos16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_lr_pred = logit.predict(X_test)\n",
        "print(f'Area under ROC curve: {roc_auc_score(y_test, y_lr_pred): 0.4f}')\n",
        "print(f'Accuracy {accuracy_score(y_test, y_lr_pred): 0.4f}')\n",
        "print(f'Weigted F1 score {f1_score(y_test, y_lr_pred, average=\"weighted\"): 0.4f}')\n",
        "print(classification_report(y_test, y_lr_pred, digits=4))\n",
        "pd.DataFrame(confusion_matrix(y_test, y_lr_pred))"
      ],
      "metadata": {
        "id": "H7IDJ0UBo4QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5\\. Save the models to a file using the pickle library\n",
        "\n",
        "\n",
        "- show that you can save a model to a file then read the model from the file that you saved\n",
        "\n",
        "<font color=\"red\"><h1>Submit Answer Below [7] :</h1></font>"
      ],
      "metadata": {
        "id": "snSPncmm-us0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "6Z3AC5GC_AJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}